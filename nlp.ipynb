{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vishesh-Goyal7/NeuroMechs/blob/Chatbot/nlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install dependencies\n",
        "!pip install transformers accelerate sentencepiece pandas"
      ],
      "metadata": {
        "collapsed": true,
        "id": "3DnyreXtceHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Import libraries\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline"
      ],
      "metadata": {
        "id": "SXLheeMvcfFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "model_id = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
        "\n",
        "login(token=\"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\")"
      ],
      "metadata": {
        "id": "oXfqmuN1jNMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16, device_map=\"auto\")\n",
        "llm_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "0zzSC9l4dukr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "xo8zeNw40Us3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Load symptom-disease dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/symptomMap.csv\")  # Or upload your CSV\n",
        "all_symptoms = df.columns[:-1].tolist()"
      ],
      "metadata": {
        "id": "0_MyRzkkdKTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: LLM helper function\n",
        "def ask_llm(user_symptom_input, known_symptoms):\n",
        "    symptom_list_str = \", \".join(known_symptoms)\n",
        "    prompt = (\n",
        "    \"You are a medical chatbot. When a user tells you a symptom, \"\n",
        "    \"identify and acknowledge it. If the user says 'done', end the list.\\n\\n\"\n",
        ")\n",
        "\n",
        "    # Extract only the list from the response\n",
        "    try:\n",
        "        extracted = eval(response.split(\"[\")[-1].split(\"]\")[0])\n",
        "        if isinstance(extracted, str):  # Convert single string to list\n",
        "            return [extracted.strip()]\n",
        "        return [sym.strip() for sym in extracted]\n",
        "    except:\n",
        "        return []"
      ],
      "metadata": {
        "id": "ERZSYPG5dVlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Function to get matching diseases\n",
        "def get_matching_diseases(symptoms):\n",
        "    if not symptoms:\n",
        "        return []\n",
        "    filtered = df.copy()\n",
        "    for symptom in symptoms:\n",
        "        if symptom in filtered.columns:\n",
        "            filtered = filtered[filtered[symptom] == 1]\n",
        "    # Access the disease column using its actual name from the DataFrame\n",
        "    # This could be 'Disease' or another name, check your CSV file\n",
        "    return filtered['Disease'].unique().tolist() # Changed 'disease' to 'Disease'"
      ],
      "metadata": {
        "id": "IK3QxlWvdYWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "symptom_cols = df.columns[1:]\n",
        "symptom_texts = [col.replace(\"_\", \" \").lower() for col in symptom_cols]\n",
        "\n",
        "symptom_embeddings = model.encode(symptom_texts, convert_to_tensor=True)\n",
        "\n",
        "def get_user_symptoms(user_input, top_k=5, similarity_threshold=0.4):\n",
        "    input_embedding = model.encode(user_input, convert_to_tensor=True)\n",
        "    cos_scores = util.cos_sim(input_embedding, symptom_embeddings)[0]\n",
        "    top_results = (cos_scores > similarity_threshold).nonzero()\n",
        "\n",
        "    # Check if top_results[0] is a string and convert to a list if necessary\n",
        "    indices = top_results[0]\n",
        "    if not isinstance(indices, torch.Tensor): # Check if indices is a Tensor and convert to list\n",
        "        indices = [int(indices)] if isinstance(indices, str) else [indices] # Convert string/int to list\n",
        "    else:\n",
        "        indices = indices.tolist() # Convert Tensor to list\n",
        "\n",
        "    matched_symptoms = [(symptom_cols[i], float(cos_scores[i])) for i in indices]  # Use the indices list\n",
        "    matched_symptoms.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    return matched_symptoms[:top_k]"
      ],
      "metadata": {
        "id": "Zva309PEdbBc",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Outside chatbot_interaction()\n",
        "def rank_diseases(matched_symptoms, df):\n",
        "    symptom_weights = dict(matched_symptoms)  # {symptom: score}\n",
        "    disease_scores = []\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        disease = row[0]\n",
        "        score = 0.0\n",
        "        for symptom, weight in symptom_weights.items():\n",
        "            if row[symptom] == 1:\n",
        "                score += weight\n",
        "        if score > 0:\n",
        "            disease_scores.append((disease, score))\n",
        "\n",
        "    disease_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "    return disease_scores"
      ],
      "metadata": {
        "id": "Pj80_UtZd8T7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_user_symptoms(user_input, top_k=5, similarity_threshold=0.4):\n",
        "    input_embedding = model.encode(user_input, convert_to_tensor=True)\n",
        "    cos_scores = util.cos_sim(input_embedding, symptom_embeddings)[0]\n",
        "    top_results = (cos_scores > similarity_threshold).nonzero()\n",
        "\n",
        "    # Check if top_results is empty\n",
        "    if top_results.size(0) == 0:  # If top_results is empty\n",
        "        return []  # Return an empty list to indicate no matches\n",
        "\n",
        "    # Check if top_results[0] is a string and convert to a list if necessary\n",
        "    indices = top_results[0] # Access the first element only if top_results is not empty\n",
        "    if not isinstance(indices, torch.Tensor): # Check if indices is a Tensor and convert to list\n",
        "        indices = [int(indices)] if isinstance(indices, str) else [indices] # Convert string/int to list\n",
        "    else:\n",
        "        indices = indices.tolist() # Convert Tensor to list\n",
        "\n",
        "    matched_symptoms = [(symptom_cols[i], float(cos_scores[i])) for i in indices]  # Use the indices list\n",
        "    matched_symptoms.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    return matched_symptoms[:top_k]"
      ],
      "metadata": {
        "id": "yYmD-MRSCmiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def match_symptom_semantic(user_input):\n",
        "    inputs = [i.strip().lower() for i in user_input.split(',')]\n",
        "    matched_symptoms = {}\n",
        "\n",
        "    for input_symptom in inputs:\n",
        "        input_embedding = model.encode(input_symptom, convert_to_tensor=True).to(symptom_embeddings.device)\n",
        "        similarities = util.cos_sim(input_embedding, symptom_embeddings)\n",
        "        best_match_idx = similarities.argmax()\n",
        "        best_match_score = similarities[0, best_match_idx].item()\n",
        "\n",
        "        if best_match_score > 0.0:\n",
        "            matched_symptoms[input_symptom] = symptom_cols[int(best_match_idx)]\n",
        "        else:\n",
        "            matched_symptoms[input_symptom] = None\n",
        "\n",
        "    return matched_symptoms"
      ],
      "metadata": {
        "id": "dLyl_sHvTJ5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def preprocess_symptoms(user_input):\n",
        "    user_input = user_input.lower()\n",
        "    user_input = re.sub(r\"\\b(i have|i'm|i am|i've got|feeling|suffering from|dealing with|experiencing|got|having)\\b\", \"\", user_input)\n",
        "    user_input = user_input.replace(\" and \", \";\").replace(\",\", \";\")\n",
        "    phrases = [p.strip().strip(\".\") for p in user_input.split(\";\") if p.strip()]\n",
        "\n",
        "    return phrases\n"
      ],
      "metadata": {
        "id": "wp1JZRDCnuQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import json\n",
        "\n",
        "def chatbot_interaction():\n",
        "    \"\"\"Manages the chatbot conversation with the user.\"\"\"\n",
        "    user_symptoms = []\n",
        "    matched_symptom_scores = []\n",
        "\n",
        "    print(\"🤖 MediBot: Hello! I'm MediBot, your personal symptom checker powered by AI.\")\n",
        "    print(\"🤖 MediBot: You can enter multiple symptoms in one go (e.g., 'fever, headache') or one by one.\")\n",
        "    print(\"           Type 'done' when you're finished.\\n\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"🧑 User: \").strip()\n",
        "        if user_input.lower() == 'done':\n",
        "            break\n",
        "\n",
        "        possible_symptoms = preprocess_symptoms(user_input)\n",
        "\n",
        "        for raw_symptom in possible_symptoms:\n",
        "            matched = match_symptom_semantic(raw_symptom)\n",
        "\n",
        "            if matched and matched not in user_symptoms:\n",
        "                # If it's a dict like {'cold': 'fever'}, get the value\n",
        "                matched_symptom = matched if isinstance(matched, str) else list(matched.values())[0]\n",
        "\n",
        "                user_symptoms.append(matched_symptom)\n",
        "\n",
        "                # Score the symptom (for future use)\n",
        "                top_match = get_user_symptoms(raw_symptom, top_k=1)\n",
        "                if top_match:\n",
        "                    matched_symptom_scores.append(top_match[0])\n",
        "\n",
        "                # Get related info from LLM\n",
        "                prompt = f\"User reports: {matched_symptom}. What else might be related? Keep the response concise and helpful for a medical chatbot context.\"\n",
        "                response = llm_pipeline(prompt, max_new_tokens=60, do_sample=True, temperature=0.7)[0]['generated_text']\n",
        "                llm_response_text = response.strip().split('User reports:')[1].strip() if 'User reports:' in response else response.strip()\n",
        "                first_sentence = llm_response_text.split('.')[0] + '.' if '.' in llm_response_text else llm_response_text\n",
        "                print(f\"🤖 MediBot: Got it. You're experiencing '{matched_symptom}'. {first_sentence}\")\n",
        "            elif raw_symptom and not matched:\n",
        "                print(f\"🤖 MediBot: Couldn't confidently match '{raw_symptom}'. Please rephrase or try another symptom.\")\n",
        "\n",
        "    if not user_symptoms:\n",
        "        print(\"\\n🤖 MediBot: I couldn't understand any symptoms. Please try again with more common descriptions.\")\n",
        "        return\n",
        "\n",
        "    print(\"\\n🔍 MediBot: Analyzing your symptoms...\")\n",
        "    print(f\"📌 Symptoms considered: {', '.join(user_symptoms)}\")\n",
        "\n",
        "    # Match diseases from dataframe (df) by symptom overlap\n",
        "    disease_scores = rank_diseases([(symptom, 1.0) for symptom in user_symptoms], df)\n",
        "\n",
        "    if disease_scores:\n",
        "        print(\"\\n🩺 MediBot: Based on your symptoms, here are some possible conditions:\\n\")\n",
        "        for idx, (disease, score) in enumerate(disease_scores, 1):\n",
        "            print(f\"   {idx}. {disease.replace('_', ' ')} (match score: {score:.2f})\")\n",
        "    else:\n",
        "        print(\"\\n🤖 MediBot: Couldn't match these symptoms to any known conditions. Please consult a medical professional.\")\n",
        "\n",
        "    # Structure the result data\n",
        "    result_data = {\n",
        "        \"date\": datetime.date.today().strftime('%Y-%m-%d'),\n",
        "        \"input_symptoms\": user_symptoms,\n",
        "        \"possible_conditions\": [\n",
        "            {\"disease\": disease.replace('_', ' '), \"match_score\": round(score, 1)}\n",
        "            for disease, score in disease_scores\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    # Save to JSON file\n",
        "    with open(\"medibot_results.json\", \"w\") as f:\n",
        "        json.dump(result_data, f, indent=4)\n",
        "\n",
        "    print(\"\\n💾 Your results have been saved to 'medibot_results.json'.\")\n",
        "\n",
        "    print(f\"\\n📅 Date: {datetime.date.today().strftime('%B %d, %Y')}\")\n",
        "    print(\"✅ Thank you for using MediBot. Stay healthy!\")\n",
        "\n",
        "chatbot_interaction()"
      ],
      "metadata": {
        "id": "fGWXUFC1j8sb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}